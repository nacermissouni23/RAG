{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "with open(\"../data/qas_v2.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    qa_dict = {item[\"ID\"]: item for item in json.load(f)}\n",
    "\n",
    "paths = glob(\"../output/**/*.json\", recursive=True)\n",
    "ocr_types = [\"gt\"]\n",
    "ret_df = []\n",
    "gen_df = []\n",
    "end_df = []\n",
    "for path in tqdm(paths):\n",
    "    if \"gpt-4o\" in path or \"qwen2_72b\" in path:\n",
    "        continue\n",
    "    basename = os.path.basename(path).removesuffix(\".json\")\n",
    "    ocr_type = os.path.basename(os.path.dirname(path))\n",
    "    if ocr_type not in ocr_types:\n",
    "        continue\n",
    "    with open(path) as f:\n",
    "        data = json.load(f)\n",
    "    if \"/retrieval/\" in path:\n",
    "        ret = basename.split(\"_\")[1]\n",
    "        llm = \"\"\n",
    "        df = ret_df\n",
    "    elif \"/generation/\" in path:\n",
    "        ret = \"\"\n",
    "        llm = \"_\".join(basename.split(\"_\")[-2:])\n",
    "        df = gen_df\n",
    "    elif \"/end2end/\" in path:\n",
    "        ret = basename.split(\"_\")[1]\n",
    "        llm = \"_\".join(basename.split(\"_\")[-2:])\n",
    "        df = end_df\n",
    "    df.extend({\n",
    "        \"id\": item[\"id\"],\n",
    "        \"ocr_type\": ocr_type,\n",
    "        \"ret\": ret,\n",
    "        \"llm\": llm,\n",
    "        \"domain\": qa_dict[item[\"id\"]][\"doc_type\"],\n",
    "        \"doc_name\": qa_dict[item[\"id\"]][\"doc_name\"].split(\"/\")[-1],\n",
    "        \"evidence_source\": qa_dict[item[\"id\"]][\"evidence_source\"],\n",
    "        \"answer_form\": qa_dict[item[\"id\"]][\"answer_form\"],\n",
    "        **item[\"metrics\"]\n",
    "    } for item in data[\"results\"] if item[\"id\"] in qa_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_df = pd.DataFrame(end_df)\n",
    "gen_df = pd.DataFrame(gen_df)\n",
    "ret_df = pd.DataFrame(ret_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gen Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "keys = [\"ocr_type\", \"ret\", \"llm\", \"domain\", \"doc_name\", \"evidence_source\", \"answer_form\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def show_types(input_df, ocr_types, metric=\"F1\", domain=False,):\n",
    "    grouby = \"evidence_source\"\n",
    "    if domain:\n",
    "        grouby = \"domain\"\n",
    "    from copy import deepcopy\n",
    "    import pandas as pd\n",
    "\n",
    "    print(input_df.columns.tolist())\n",
    "    print(metric)\n",
    "    \n",
    "    input_df = deepcopy(input_df)\n",
    "    input_df[metric] = input_df[metric] * 100\n",
    "    \n",
    "    evidence_order = {'text': 0, 'table': 1, 'formula': 2, 'chart': 3, 'reading_order': 4, 'multi': 5, 'all': 6}\n",
    "    \n",
    "    \n",
    "    print(\"BEFORE FILTER:\", input_df.shape, input_df.columns.tolist())\n",
    "\n",
    "    df_filtered = input_df[input_df[\"ocr_type\"].isin(ocr_types)]\n",
    "\n",
    "    print(\"AFTER FILTER:\", df_filtered.shape, df_filtered.columns.tolist())\n",
    "    print(\"OCR TYPES IN DF:\", input_df[\"ocr_type\"].unique())\n",
    "    print(\"OCR TYPES REQUESTED:\", ocr_types)\n",
    "    \n",
    "    \n",
    "    result = (\n",
    "        df_filtered[keys + [metric]]\n",
    "        .groupby([\"ocr_type\", grouby])\n",
    "        .agg(\n",
    "            mean_metric=(metric, 'mean'),\n",
    "            count=(metric, 'count')\n",
    "        )\n",
    "    )\n",
    "    overall = (\n",
    "        df_filtered[keys + [metric]]\n",
    "        .groupby(\"ocr_type\")\n",
    "        .agg(\n",
    "            mean_metric=(metric, 'mean'),\n",
    "            count=(metric, 'count')\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    overall[grouby] = \"all\"\n",
    "    overall = overall.set_index([\"ocr_type\", grouby])\n",
    "    \n",
    "    final_result = pd.concat([result, overall])\n",
    "    final_result = final_result.reset_index()\n",
    "    final_result['evidence_order_value'] = final_result[grouby].map(evidence_order)\n",
    "    final_result = final_result.sort_values(by=['ocr_type', 'evidence_order_value'])\n",
    "    final_result = final_result.drop(columns=['evidence_order_value']).set_index(['ocr_type', grouby])\n",
    "    \n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "lcs\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'lcs'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m display(\u001b[43mshow_types\u001b[49m\u001b[43m(\u001b[49m\u001b[43mret_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mocr_types\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlcs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdomain\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m.round(\u001b[32m1\u001b[39m).pivot_table(index=\u001b[33m'\u001b[39m\u001b[33mevidence_source\u001b[39m\u001b[33m'\u001b[39m, columns=\u001b[33m'\u001b[39m\u001b[33mocr_type\u001b[39m\u001b[33m'\u001b[39m, values=\u001b[33m'\u001b[39m\u001b[33mmean_metric\u001b[39m\u001b[33m'\u001b[39m, aggfunc=\u001b[38;5;28;01mlambda\u001b[39;00m x: x))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mshow_types\u001b[39m\u001b[34m(input_df, ocr_types, metric, domain)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(metric)\n\u001b[32m     13\u001b[39m input_df = deepcopy(input_df)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m input_df[metric] = \u001b[43minput_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m]\u001b[49m * \u001b[32m100\u001b[39m\n\u001b[32m     16\u001b[39m evidence_order = {\u001b[33m'\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m0\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtable\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m1\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mformula\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m2\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mchart\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m3\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mreading_order\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m4\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmulti\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m5\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mall\u001b[39m\u001b[33m'\u001b[39m: \u001b[32m6\u001b[39m}\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBEFORE FILTER:\u001b[39m\u001b[33m\"\u001b[39m, input_df.shape, input_df.columns.tolist())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\RAG\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\RAG\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\range.py:417\u001b[39m, in \u001b[36mRangeIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    415\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    416\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Hashable):\n\u001b[32m--> \u001b[39m\u001b[32m417\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[32m    418\u001b[39m \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'lcs'"
     ]
    }
   ],
   "source": [
    "display(show_types(ret_df, ocr_types, \"lcs\", domain=False).round(1).pivot_table(index='evidence_source', columns='ocr_type', values='mean_metric', aggfunc=lambda x: x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(show_types(gen_df, ocr_types, domain=False).round(1).pivot_table(index='evidence_source', columns='ocr_type', values='mean_metric', aggfunc=lambda x: x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(show_types(end_df, ocr_types, domain=False).round(1).pivot_table(index='evidence_source', columns='ocr_type', values='mean_metric', aggfunc=lambda x: x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
